{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d33ac88",
   "metadata": {},
   "source": [
    "# HW2 - Bias in Data and Prediction - DSCI 531 - Spring 2024\n",
    "\n",
    "### Please complete the code or analysis under \"TODO\". 100pts in total. You should run every cell and keep all the outputs before submitting. Failing to include your outputs will result in zero points.\n",
    "### Please keep academic integrity in mind. Plagiarism will be taken seriously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c56c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c75bf7",
   "metadata": {},
   "source": [
    "## 1. Implement Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c8b61d",
   "metadata": {},
   "source": [
    "### 1.1 Fairness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5455541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You are NOT allowed to use off-the-shelf fairness packages like ai360\n",
    "\n",
    "def stat_parity(preds, sens):\n",
    "    '''\n",
    "    :preds: numpy array of the model predictions. Consisting of 0s and 1s\n",
    "    :sens: numpy array of the sensitive features. Consisting of 0s and 1s\n",
    "    :return: the statistical parity. no need to take the absolute value\n",
    "    '''\n",
    "    \n",
    "    count_one = 0 # Positive Prediction for 0 of sens\n",
    "    count_zero = 0 # Positive Prediction for 1 of sens\n",
    "    num_one = sum(sens) # number of class 1 of sens\n",
    "    num_zero = len(sens) - num_one # number of class 0 of sens\n",
    "    \n",
    "    for i in range(len(sens)):\n",
    "        if sens[i]==0: # case of 0 of sens\n",
    "            if preds[i]==1:\n",
    "                count_zero +=1\n",
    "            else:\n",
    "                continue\n",
    "        else: # case of 1 of sens\n",
    "            if preds[i]==1:\n",
    "                count_one +=1\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "                \n",
    "    if num_one != 0:\n",
    "        \n",
    "        parity1 = count_one/num_one\n",
    "    else:\n",
    "        parity1 =0 \n",
    "        \n",
    "    if num_zero != 0:\n",
    "        \n",
    "        parity0 = count_zero/num_zero\n",
    "    else:\n",
    "        parity0 =0 \n",
    "        \n",
    "    parity = parity1-parity0\n",
    "    # TODO. 7.5pts\n",
    "    return parity\n",
    "\n",
    "\n",
    "def eq_oppo(preds, sens, labels):\n",
    "    '''\n",
    "    :preds: numpy array of the model predictions. Consisting of 0s and 1s\n",
    "    :sens: numpy array of the sensitive features. Consisting of 0s and 1s\n",
    "    :labels: numpy array of the ground truth labels of the outcome. Consisting of 0s and 1s\n",
    "    :return: the statistical parity. no need to take the absolute value\n",
    "    '''\n",
    "    \n",
    "    TP_one = np.sum((preds == 1) & (sens == 1) & (labels == 1))\n",
    "    AP_one = np.sum((sens == 1) & (labels == 1)) # this will include False Negative because FN is actually positive\n",
    "\n",
    "    TP_zero = np.sum((preds == 1) & (sens == 0) & (labels == 1))\n",
    "    AP_zero = np.sum((sens == 0) & (labels == 1))\n",
    "    \n",
    "    if AP_one != 0:\n",
    "        \n",
    "        eq_one = TP_one/AP_one\n",
    "    else:\n",
    "        eq_one = 0\n",
    "        \n",
    "    if AP_zero!=0:\n",
    "        \n",
    "        eq_zero = TP_zero/AP_zero\n",
    "    else:\n",
    "        eq_zero = 0\n",
    "    \n",
    "    # TODO. 7.5pts\n",
    "    return eq_one-eq_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d3a213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 -0.125\n",
      "-0.75 0.5\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# Test your implemented fairness metrics using the code below\n",
    "# Don't change the code in this cell\n",
    "\n",
    "# test case 1\n",
    "preds = np.array([1, 0, 1, 0, 0, 1, 0, 0, 0, 1])\n",
    "sens = np.array([1, 1, 0, 1, 1, 1, 0, 1, 1, 1])\n",
    "labels = np.array([0, 1, 0, 1, 0, 1, 1, 1, 0, 1])\n",
    "print(eq_oppo(preds, sens, labels), stat_parity(preds, sens))\n",
    "\n",
    "# test case 2\n",
    "preds = np.array([1, 1, 0, 1, 0, 1, 0, 0, 1, 1])\n",
    "sens = np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
    "labels = np.array([0, 1, 0, 1, 0, 1, 1, 0, 0, 0])\n",
    "print(eq_oppo(preds, sens, labels), stat_parity(preds, sens))\n",
    "\n",
    "\n",
    "# test case 3\n",
    "preds = np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
    "sens = np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
    "labels = np.array([0, 1, 0, 1, 0, 1, 1, 0, 0, 0])\n",
    "print(eq_oppo(preds, sens, labels), stat_parity(preds, sens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6c1b21",
   "metadata": {},
   "source": [
    "### 1.2 Preprocessing DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3aef19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler \n",
    "def process_dfs(df_train_x, df_test_x, categ_cols):\n",
    "    '''\n",
    "    Pre-process the features of the training set and the test set, not including the outcome column.\n",
    "    Convert categorical features (nominal & ordinal features) to one-hot encodings.\n",
    "    Normalize the numerical features into [0, 1].\n",
    "    We process training set and the test set together in order to make sure that \n",
    "    the encodings are consistent between them.\n",
    "    For example, if one class is encoded as 001 and another class is encoded as 010 in the training set,\n",
    "    you should follow this mapping for the test set too.\n",
    "    \n",
    "    :df_train: the dataframe of the training data\n",
    "    :df_test: the dataframe of the test data\n",
    "    :categ_cols: the column names of the categorical features. the rest features are treated as numerical ones.\n",
    "    :return: the processed training data and test data, both should be numpy arrays, instead of DataFrames\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    train_x = pd.get_dummies(df_train_x, columns = categ_cols, dtype=int)\n",
    "    test_x = pd.get_dummies(df_test_x, columns = categ_cols, dtype=int)\n",
    "    \n",
    "    test_x = test_x.reindex(columns=train_x.columns, fill_value=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    train_x = scaler.fit_transform(train_x)\n",
    "    test_x = scaler.transform(test_x) # use the same scaler\n",
    "        \n",
    "    \n",
    "    # TODO. 15pts\n",
    "    return train_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54b0b715",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.71428571 1.         0.         0.         1.         0.\n",
      "  0.        ]\n",
      " [1.         1.         0.         0.         0.         1.\n",
      "  0.        ]\n",
      " [0.         0.         1.         0.         1.         0.\n",
      "  0.        ]\n",
      " [0.28571429 0.         0.         1.         0.         0.\n",
      "  1.        ]]\n",
      "\n",
      "[[1.57142857 1.         0.         0.         0.         1.\n",
      "  0.        ]\n",
      " [0.57142857 0.         0.         1.         1.         0.\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Test your implemented data preprocessing function\n",
    "# DO NOT change the code in this cell\n",
    "\n",
    "df_train_x = pd.DataFrame([\n",
    "    [ 'big', 10, 'blue',],\n",
    "    [ 'big', 12, 'red',],\n",
    "    ['medium', 5, 'blue'],\n",
    "    ['small', 7, 'yellow']\n",
    "], columns=['size', 'height', 'color'])\n",
    "\n",
    "df_test_x = pd.DataFrame([\n",
    "    [ 'big', 16, 'red',],\n",
    "    ['small', 9, 'blue']\n",
    "], columns=['size', 'height', 'color'])\n",
    "\n",
    "train_data_x, test_data_x = process_dfs(df_train_x, df_test_x, categ_cols=['size', 'color'])\n",
    "print(train_data_x)\n",
    "print()\n",
    "print(test_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18bb8c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 7)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eae612fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 7)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fc8867",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34361f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_adult = pd.read_csv('adult-train.csv', sep=', ', engine='python')\n",
    "df_test_adult = pd.read_csv('adult-test.csv', sep=', ', engine='python')\n",
    "df_train_adult['sex'] = df_train_adult['sex'].map({'Male': 0, 'Female': 1})\n",
    "df_test_adult['sex'] = df_test_adult['sex'].map({'Male': 0, 'Female': 1})\n",
    "df_train_adult['income'] = df_train_adult['income'].map({'<=50K': 0, '>50K': 1})\n",
    "df_test_adult['income'] = df_test_adult['income'].map({'<=50K': 0, '>50K': 1})\n",
    "\n",
    "\n",
    "df_train_german = pd.read_csv('german-train.csv')\n",
    "df_test_german = pd.read_csv('german-test.csv')\n",
    "df_train_german['age'] = df_train_german['age'].apply(lambda x: 1 if x >= 33 else 0)\n",
    "df_test_german['age'] = df_test_german['age'].apply(lambda x: 1 if x>=33 else 0)\n",
    "df_train_german['credit_status'] = df_train_german['credit_status'].map({2:0, 1:1})\n",
    "df_test_german['credit_status'] = df_test_german['credit_status'].map({2:0, 1:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "498e89dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race  sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    0   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    0   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    0   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    0   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black    1   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country  income  \n",
       "0          2174             0              40  United-States       0  \n",
       "1             0             0              13  United-States       0  \n",
       "2             0             0              40  United-States       0  \n",
       "3             0             0              40  United-States       0  \n",
       "4             0             0              40           Cuba       0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e950c415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checking_account</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_account</th>\n",
       "      <th>present_employment_since</th>\n",
       "      <th>installment_rate</th>\n",
       "      <th>personal_status_sex</th>\n",
       "      <th>other_debtors</th>\n",
       "      <th>...</th>\n",
       "      <th>property</th>\n",
       "      <th>age</th>\n",
       "      <th>other_installment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>num_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>num_people_liable</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>credit_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A14</td>\n",
       "      <td>21</td>\n",
       "      <td>A32</td>\n",
       "      <td>A41</td>\n",
       "      <td>5248</td>\n",
       "      <td>A65</td>\n",
       "      <td>A73</td>\n",
       "      <td>1</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A123</td>\n",
       "      <td>0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A11</td>\n",
       "      <td>24</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>1987</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A151</td>\n",
       "      <td>1</td>\n",
       "      <td>A172</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14</td>\n",
       "      <td>36</td>\n",
       "      <td>A32</td>\n",
       "      <td>A49</td>\n",
       "      <td>5742</td>\n",
       "      <td>A62</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A123</td>\n",
       "      <td>0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A14</td>\n",
       "      <td>36</td>\n",
       "      <td>A32</td>\n",
       "      <td>A49</td>\n",
       "      <td>7409</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>3</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A122</td>\n",
       "      <td>1</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A14</td>\n",
       "      <td>6</td>\n",
       "      <td>A34</td>\n",
       "      <td>A42</td>\n",
       "      <td>1221</td>\n",
       "      <td>A65</td>\n",
       "      <td>A73</td>\n",
       "      <td>1</td>\n",
       "      <td>A94</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A122</td>\n",
       "      <td>0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  checking_account  duration credit_history purpose  credit_amount  \\\n",
       "0              A14        21            A32     A41           5248   \n",
       "1              A11        24            A32     A43           1987   \n",
       "2              A14        36            A32     A49           5742   \n",
       "3              A14        36            A32     A49           7409   \n",
       "4              A14         6            A34     A42           1221   \n",
       "\n",
       "  savings_account present_employment_since  installment_rate  \\\n",
       "0             A65                      A73                 1   \n",
       "1             A61                      A73                 2   \n",
       "2             A62                      A74                 2   \n",
       "3             A65                      A75                 3   \n",
       "4             A65                      A73                 1   \n",
       "\n",
       "  personal_status_sex other_debtors  ...  property age  \\\n",
       "0                 A93          A101  ...      A123   0   \n",
       "1                 A93          A101  ...      A121   0   \n",
       "2                 A93          A101  ...      A123   0   \n",
       "3                 A93          A101  ...      A122   1   \n",
       "4                 A94          A101  ...      A122   0   \n",
       "\n",
       "   other_installment_plans housing num_credits   job num_people_liable  \\\n",
       "0                     A143    A152           1  A173                 1   \n",
       "1                     A143    A151           1  A172                 2   \n",
       "2                     A143    A152           2  A173                 1   \n",
       "3                     A143    A152           2  A173                 1   \n",
       "4                     A143    A152           2  A173                 1   \n",
       "\n",
       "   telephone foreign_worker credit_status  \n",
       "0       A191           A201             1  \n",
       "1       A191           A201             0  \n",
       "2       A192           A201             1  \n",
       "3       A191           A201             1  \n",
       "4       A191           A201             1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_german.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c297f2",
   "metadata": {},
   "source": [
    "## 3. Explore fairness in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78093a00",
   "metadata": {},
   "source": [
    "### 3.1 statical analysis on protected feature and outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0747aee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3138370951913641 0.11367818442036394\n",
      "0.6636363636363637 0.7594594594594595\n"
     ]
    }
   ],
   "source": [
    "# Adult\n",
    "# calculate the mean income of two protected groups. only use the training data df_train_adult. \n",
    "# TODO. 3pts. The starter code below just indicate what you need to output in your code.\n",
    "mean_income1_adult = np.mean(df_train_adult.loc[df_train_adult['sex']==0]['income'])\n",
    "mean_income2_adult = np.mean(df_train_adult.loc[df_train_adult['sex']==1]['income'])\n",
    "\n",
    "print(mean_income1_adult, mean_income2_adult)\n",
    "\n",
    "\n",
    "# German\n",
    "# calculate the mean credit status of two protected groups. only use the training data df_train_german. \n",
    "# TODO. 3pts. The starter code below just indicate what you need to output in your code.\n",
    "mean_credit1_german = np.mean(df_train_german.loc[df_train_german['age']==0]['credit_status'])\n",
    "mean_credit2_german = np.mean(df_train_german.loc[df_train_german['age']==1]['credit_status'])\n",
    "\n",
    "print(mean_credit1_german, mean_credit2_german)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9836be9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0049802626425791505\n"
     ]
    }
   ],
   "source": [
    "# t-test between outcome of two protected groups. only use the training data df_train_adult/german.\n",
    "from scipy.stats import ttest_ind_from_stats\n",
    "\n",
    "# Adult\n",
    "# TODO. 1.5pts. The starter code below just indicate what you need to output in your code.\n",
    "std_income1_adult = np.std(df_train_adult.loc[df_train_adult['sex']==0]['income'])\n",
    "std_income2_adult = np.std(df_train_adult.loc[df_train_adult['sex']==1]['income'])\n",
    "num_income1_adult = len(df_train_adult.loc[df_train_adult['sex']==0]['income'])\n",
    "num_income2_adult = len(df_train_adult.loc[df_train_adult['sex']==1]['income'])\n",
    "# p_value_adult = \n",
    "\n",
    "# pool_std = np.sqrt((std_income1_adult**2 + std_income2_adult**2) / 2)\n",
    "\n",
    "t_stat_adult, p_value_adult = ttest_ind_from_stats(mean1=mean_income1_adult, std1=std_income1_adult, nobs1=num_income1_adult,\n",
    "                                       mean2=mean_income2_adult, std2=std_income2_adult, nobs2=num_income2_adult,\n",
    "                                       equal_var=True)\n",
    "\n",
    "\n",
    "# # german\n",
    "# # TODO. 1.5pts. The starter code below just indicate what you need to output in your code.\n",
    "# p_value_german = \n",
    "\n",
    "std_credit1_german = np.std(df_train_german.loc[df_train_german['age']==0]['credit_status'])\n",
    "std_credit2_german = np.std(df_train_german.loc[df_train_german['age']==1]['credit_status'])\n",
    "num_credit1_german = len(df_train_german.loc[df_train_german['age']==0]['credit_status'])\n",
    "num_credit2_german = len(df_train_german.loc[df_train_german['age']==1]['credit_status'])\n",
    "\n",
    "t_stat_german, p_value_german = ttest_ind_from_stats(mean1=mean_credit1_german, std1=std_credit1_german, nobs1=num_credit1_german,\n",
    "                                       mean2=mean_credit2_german, std2=std_credit2_german, nobs2=num_credit2_german,\n",
    "                                       equal_var=True)\n",
    "print(p_value_adult, p_value_german)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71338e78",
   "metadata": {},
   "source": [
    "### From the p_values, are the results significant for Adult and German? How do you explain them?\n",
    "### <span style=\"color:red\">Please type your response here.</span> 3 pts\n",
    "Since both p values for Adult and German t tests are smaller than 0.05, we can say that there is a significant difference between the two groups of Adult dataset. So does the two groups of German dataset. We reject the null hypothesis that there's no difference between two protected groups. \n",
    "\n",
    "Since the two groups for Adult t test is based on sex, that means there is bias against sex for Adult's income. Similarly, the two groups for German t test is based on Age, that means there could be bias against age for German's credit status."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee79391",
   "metadata": {},
   "source": [
    "### 3.2 Explore Fairness in Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "212507b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 103) (15060, 103) (30162,) (15060,)\n",
      "(700, 61) (300, 61) (700,) (300,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "# Dont't change code in this cell\n",
    "\n",
    "'''\n",
    ":train_x: the features in the training set (including the sensitive features), shape: N_train x d\n",
    ":train_y: the outcome in the training set, shape: N_train\n",
    ":test_x: the features in the test set (including the sensitive features), shape: N_test x d\n",
    ":test_y: the outcome in the test set, shape: N_test\n",
    ":test_sens: the sensitive/protected feature in the test set, shape: N_test\n",
    "All of them are processed numpy arrays that are ready for algorithms.\n",
    "'''\n",
    "\n",
    "\n",
    "# adult\n",
    "# the outcome (income) is the last column\n",
    "df_train_x_adult = df_train_adult.iloc[:, :-1]\n",
    "df_train_y_adult = df_train_adult.iloc[:, -1]\n",
    "df_test_x_adult = df_test_adult.iloc[:, :-1]\n",
    "df_test_y_adult = df_test_adult.iloc[:, -1]\n",
    "df_test_sens_adult = df_test_adult['sex']\n",
    "\n",
    "train_x_adult, test_x_adult = process_dfs(df_train_x_adult, df_test_x_adult, \n",
    "                                                   ['workclass', 'education','marital-status',\n",
    "                                                    'occupation','relationship','race',\n",
    "                                                    'native-country'])\n",
    "train_y_adult = df_train_y_adult.values\n",
    "test_y_adult = df_test_y_adult.values\n",
    "test_sens_adult = df_test_sens_adult.values\n",
    "\n",
    "# german\n",
    "# the outcome (credit status) is the last column\n",
    "df_train_x_german = df_train_german.iloc[:, :-1]\n",
    "df_train_y_german = df_train_german.iloc[:, -1]\n",
    "df_test_x_german = df_test_german.iloc[:, :-1]\n",
    "df_test_y_german = df_test_german.iloc[:, -1]\n",
    "df_test_sens_german = df_test_german['age']\n",
    "\n",
    "train_x_german, test_x_german = process_dfs(df_train_x_german, df_test_x_german,\n",
    "                                                     ['checking_account', 'credit_history', \n",
    "                                                      'purpose', 'savings_account', 'present_employment_since', \n",
    "                                                      'personal_status_sex', 'other_debtors',\n",
    "                                                     'property', 'other_installment_plans',\n",
    "                                                     'housing', 'job', 'telephone', 'foreign_worker'])\n",
    "train_y_german = df_train_y_german.values\n",
    "test_y_german = df_test_y_german.values\n",
    "test_sens_german = df_test_sens_german.values\n",
    "\n",
    "print(train_x_adult.shape, test_x_adult.shape, train_y_adult.shape, test_y_adult.shape)\n",
    "print(train_x_german.shape, test_x_german.shape, train_y_german.shape, test_y_german.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4060f120",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8458167330677291 -0.18351302412645248 -0.1010069968257522\n",
      "0.76 0.09657196211818064 0.08974358974358976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/will/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# train a classifier to predict the outcome y from features x\n",
    "# training: train_x --> train_y; test: test_x --> preds\n",
    "# logistic regression model is recommended\n",
    "# sklearn is allowed to use\n",
    "\n",
    "\n",
    "# Adult 5 pts\n",
    "\n",
    "# initialize the model\n",
    "# TODO.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# train/fit the model with train_x_adult and train_y_adult\n",
    "# TODO.\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(train_x_adult,train_y_adult)\n",
    "\n",
    "\n",
    "# predict the outcome from test_x_adult\n",
    "# TODO. The starter code below just indicate what you need to output in your code.\n",
    "preds = model1.predict(test_x_adult)\n",
    "\n",
    "\n",
    "# report acc and two fairness metrics. \n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_y_adult, preds)\n",
    "stat_p = stat_parity(preds, test_sens_adult)\n",
    "eq_op = eq_oppo(preds, test_sens_adult, test_y_adult)\n",
    "print(acc, stat_p, eq_op)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# German 5 pts\n",
    "\n",
    "# initialize the model\n",
    "# TODO.\n",
    "\n",
    "\n",
    "# train/fit the model with train_x_german and train_y_german\n",
    "# TODO.\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(train_x_german,train_y_german)\n",
    "\n",
    "# predict the outcome from test_x_german\n",
    "# TODO. The starter code below just indicate what you need to output in your code.\n",
    "preds = model2.predict(test_x_german)\n",
    "\n",
    "\n",
    "# report acc and two fairness metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_y_german, preds)\n",
    "stat_p = stat_parity(preds, test_sens_german)\n",
    "eq_op = eq_oppo(preds, test_sens_german, test_y_german)\n",
    "print(acc, stat_p, eq_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde8e5d4",
   "metadata": {},
   "source": [
    "## 4. Explore possible ways to mitigate bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b955793",
   "metadata": {},
   "source": [
    "### 4. 1 remove protected attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7f484b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 102) (15060, 102)\n",
      "(700, 60) (300, 60)\n"
     ]
    }
   ],
   "source": [
    "# Adult\n",
    "# remove the sex column from df_train_x_adult and df_test_x_adult. \n",
    "# You shouldn't do it in-place. In other words, do not modify df_train_x_adult or df_test_x_adult\n",
    "# TODO. 4pts. The starter code below just indicate what you need to output in your code.\n",
    "df_train_x_no_sens_adult = df_train_x_adult.loc[:, ~df_train_x_adult.columns.isin(['sex'])]\n",
    "df_test_x_no_sens_adult = df_test_x_adult.loc[:, ~df_test_x_adult.columns.isin(['sex'])]\n",
    "\n",
    "\n",
    "train_x_adult, test_x_adult = process_dfs(df_train_x_no_sens_adult, df_test_x_no_sens_adult, \n",
    "                                                   ['workclass', 'education','marital-status',\n",
    "                                                    'occupation','relationship','race',\n",
    "                                                    'native-country'])\n",
    "\n",
    "\n",
    "# German\n",
    "# remove age column from df_train_x_german and df_test_x_german\n",
    "# You shouldn't do it in-place. In other words, do not modify df_train_x_german or df_test_x_german\n",
    "# TODO. 4pts. The starter code below just indicate what you need to output in your code.\n",
    "df_train_x_no_sens_german = df_train_x_german.loc[:, ~df_train_x_german.columns.isin(['age'])]\n",
    "df_test_x_no_sens_german = df_test_x_german.loc[:, ~df_test_x_german.columns.isin(['age'])]\n",
    "\n",
    "\n",
    "train_x_german, test_x_german = process_dfs(df_train_x_no_sens_german, df_test_x_no_sens_german,\n",
    "                                                     ['checking_account', 'credit_history', \n",
    "                                                      'purpose', 'savings_account', 'present_employment_since', \n",
    "                                                      'personal_status_sex', 'other_debtors',\n",
    "                                                     'property', 'other_installment_plans',\n",
    "                                                     'housing', 'job', 'telephone', 'foreign_worker'])\n",
    "\n",
    "\n",
    "print(train_x_adult.shape, test_x_adult.shape)\n",
    "print(train_x_german.shape, test_x_german.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4145617a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8457503320053121 -0.17481028073158084 -0.0711906599316483\n",
      "0.7666666666666667 0.08323329331732687 0.07932692307692313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/will/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# train a classifier to predict the outcome y from features x (with protected feature removed)\n",
    "# training: train_x --> train_y; test: test_x --> preds\n",
    "# logistic regression model is recommended\n",
    "# sklearn is allowed to use\n",
    "# Just use the code in 3.2 again\n",
    "\n",
    "\n",
    "# Adult 4 pts\n",
    "\n",
    "# initialize the model\n",
    "# TODO.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model3 = LogisticRegression()\n",
    "# train/fit the model with train_x_adult and train_y_adult\n",
    "# TODO.\n",
    "\n",
    "model3.fit(train_x_adult,train_y_adult)\n",
    "\n",
    "# predict the outcome from test_x_adult\n",
    "# TODO. The starter code below just indicate what you need to output in your code.\n",
    "preds = model3.predict(test_x_adult)\n",
    "\n",
    "# report acc and two fairness metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_y_adult, preds)\n",
    "stat_p = stat_parity(preds, test_sens_adult)\n",
    "eq_op = eq_oppo(preds, test_sens_adult, test_y_adult)\n",
    "print(acc, stat_p, eq_op)\n",
    "\n",
    "\n",
    "\n",
    "# German 4 pts\n",
    "\n",
    "# initialize the model\n",
    "# TODO.\n",
    "model4 = LogisticRegression()\n",
    "\n",
    "# train/fit the model with train_x_german and train_y_german\n",
    "# TODO.\n",
    "model4.fit(train_x_german,train_y_german)\n",
    "\n",
    "# predict the outcome from test_x_german\n",
    "# TODO. The starter code below just indicate what you need to output in your code.\n",
    "preds = model4.predict(test_x_german)\n",
    "\n",
    "# report acc and two fairness metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_y_german, preds)\n",
    "stat_p = stat_parity(preds, test_sens_german)\n",
    "eq_op = eq_oppo(preds, test_sens_german, test_y_german)\n",
    "print(acc, stat_p, eq_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0face94",
   "metadata": {},
   "source": [
    "### According to the results, how are the accuracy, stat parity and eq oppo different from the original model? Does explicitly removing the sensitive feature help in mitigating bias? Why or why not?\n",
    "### <span style=\"color:red\">Please type your response here.</span> 4 points\n",
    "Accuracy wise, the results between having the sensitive feature and removing the sensitive features are very similar. Equalized opportunity and statistical parity wise, we do see smaller values if removing the sensitive feature. \n",
    "\n",
    "Explicitly removing the sensitive feature can help in mitigating bias since there is a definite reduction in bias that can be factored by sex, age, or other sensitive features. The model thus can perform without relying on these sensitive features. However, there might be other factors (proxies) that correlate with sex and age and thus cause bias. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2279414",
   "metadata": {},
   "source": [
    "### 4.2 Augmenting the training set\n",
    "\n",
    "#### See the example in Figure 1 of https://dl.acm.org/doi/pdf/10.1145/3375627.3375865"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f22eeb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30157</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30158</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30159</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30160</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30161</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt   education  education-num  \\\n",
       "0       39         State-gov   77516   Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311   Bachelors             13   \n",
       "2       38           Private  215646     HS-grad              9   \n",
       "3       53           Private  234721        11th              7   \n",
       "4       28           Private  338409   Bachelors             13   \n",
       "...    ...               ...     ...         ...            ...   \n",
       "30157   27           Private  257302  Assoc-acdm             12   \n",
       "30158   40           Private  154374     HS-grad              9   \n",
       "30159   58           Private  151910     HS-grad              9   \n",
       "30160   22           Private  201490     HS-grad              9   \n",
       "30161   52      Self-emp-inc  287927     HS-grad              9   \n",
       "\n",
       "           marital-status         occupation   relationship   race  sex  \\\n",
       "0           Never-married       Adm-clerical  Not-in-family  White    0   \n",
       "1      Married-civ-spouse    Exec-managerial        Husband  White    0   \n",
       "2                Divorced  Handlers-cleaners  Not-in-family  White    0   \n",
       "3      Married-civ-spouse  Handlers-cleaners        Husband  Black    0   \n",
       "4      Married-civ-spouse     Prof-specialty           Wife  Black    1   \n",
       "...                   ...                ...            ...    ...  ...   \n",
       "30157  Married-civ-spouse       Tech-support           Wife  White    1   \n",
       "30158  Married-civ-spouse  Machine-op-inspct        Husband  White    0   \n",
       "30159             Widowed       Adm-clerical      Unmarried  White    1   \n",
       "30160       Never-married       Adm-clerical      Own-child  White    0   \n",
       "30161  Married-civ-spouse    Exec-managerial           Wife  White    1   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country  \n",
       "0              2174             0              40  United-States  \n",
       "1                 0             0              13  United-States  \n",
       "2                 0             0              40  United-States  \n",
       "3                 0             0              40  United-States  \n",
       "4                 0             0              40           Cuba  \n",
       "...             ...           ...             ...            ...  \n",
       "30157             0             0              38  United-States  \n",
       "30158             0             0              40  United-States  \n",
       "30159             0             0              40  United-States  \n",
       "30160             0             0              20  United-States  \n",
       "30161         15024             0              40  United-States  \n",
       "\n",
       "[30162 rows x 14 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_x_adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "71a69738",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60324, 14) (60324,)\n",
      "(60324, 103) (15060, 103) (60324,)\n",
      "(1400, 20) (1400,) (1400,)\n",
      "(1400, 61) (300, 61)\n"
     ]
    }
   ],
   "source": [
    "# Adult\n",
    "# create a synthetic training set by duplicating df_train_x_adult and df_train_y_adult\n",
    "# after duplicating flip sex in the synthetic set\n",
    "# You shouldn't do it in-place. In other words, do not modify df_train_x_adult or df_train_y_adult\n",
    "# TODO. 8pts. The starter code below just indicate what you need to output in your code.\n",
    "df_train_x_syn_adult = df_train_x_adult.copy()\n",
    "df_train_x_syn_adult['sex'] = df_train_x_syn_adult['sex'].apply(lambda x: 1 if x==0 else 0)\n",
    "\n",
    "df_train_y_syn_adult = df_train_y_adult.copy()\n",
    "# df_train_y_syn_adult['income'] = df_train_y_syn_adult['income'].apply(lambda x: 1 if x==0 else 0)\n",
    "\n",
    "\n",
    "# augment the original training set by the synthetic set. In other words, concatenate them\n",
    "df_train_x_aug_adult = pd.concat((df_train_x_adult, df_train_x_syn_adult))\n",
    "df_train_y_aug_adult = pd.concat((df_train_y_adult, df_train_y_syn_adult))\n",
    "\n",
    "print(df_train_x_aug_adult.shape, df_train_y_aug_adult.shape)\n",
    "\n",
    "\n",
    "train_x_adult, test_x_adult = process_dfs(df_train_x_aug_adult, df_test_x_adult, \n",
    "                                                   ['workclass', 'education','marital-status',\n",
    "                                                    'occupation','relationship','race',\n",
    "                                                    'native-country'])\n",
    "train_y_adult = df_train_y_aug_adult.values\n",
    "print(train_x_adult.shape, test_x_adult.shape, train_y_adult.shape)\n",
    "\n",
    "\n",
    "\n",
    "# German\n",
    "# create a synthetic training set by duplicating df_train_x_german and df_train_y_german\n",
    "# after duplicating flip age in the synthetic set.\n",
    "# You shouldn't do it in-place. In other words, do not modify df_train_x_german or df_train_y_german\n",
    "# TODO. 8pts. The starter code below just indicate what you need to output in your code.\n",
    "df_train_x_syn_german = df_train_x_german.copy()\n",
    "df_train_x_syn_german['age'] = df_train_x_syn_german['age'].apply(lambda x: 1 if x==0 else 0)\n",
    "\n",
    "df_train_y_syn_german = df_train_y_german.copy()\n",
    "\n",
    "# augment the original training set by the synthetic set. In other words, concatenate them\n",
    "df_train_x_aug_german = pd.concat((df_train_x_german, df_train_x_syn_german))\n",
    "df_train_y_aug_german = pd.concat((df_train_y_german, df_train_y_syn_german))\n",
    "\n",
    "train_y_german = df_train_y_aug_german.values\n",
    "\n",
    "print(df_train_x_aug_german.shape, df_train_y_aug_german.shape, train_y_german.shape)\n",
    "\n",
    "\n",
    "train_x_german, test_x_german = process_dfs(df_train_x_aug_german, df_test_x_german,\n",
    "                                                     ['checking_account', 'credit_history', \n",
    "                                                      'purpose', 'savings_account', 'present_employment_since', \n",
    "                                                      'personal_status_sex', 'other_debtors',\n",
    "                                                     'property', 'other_installment_plans',\n",
    "                                                     'housing', 'job', 'telephone', 'foreign_worker'])\n",
    "print(train_x_german.shape, test_x_german.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e1791c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847011952191235 -0.1749751881616645 -0.07057717386275164\n",
      "0.77 0.07643057222889149 0.07932692307692313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/will/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# train a classifier to predict the outcome y from features x on the augmented training data\n",
    "# training: train_x --> train_y; test: test_x --> preds\n",
    "# logistic regression model is recommended\n",
    "# sklearn is allowed to use\n",
    "# Just use the code in 3.2 again\n",
    "\n",
    "\n",
    "# Adult 4 pts\n",
    "\n",
    "# initialize the model\n",
    "# TODO.\n",
    "model5 = LogisticRegression()\n",
    "\n",
    "# train/fit the model with train_x_adult and train_y_adult\n",
    "# TODO.\n",
    "\n",
    "model5.fit(train_x_adult,train_y_adult)\n",
    "\n",
    "# predict the outcome from test_x_adult\n",
    "# TODO. The starter code below just indicate what you need to output in your code.\n",
    "preds = model5.predict(test_x_adult)\n",
    "\n",
    "# report acc and two fairness metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_y_adult, preds)\n",
    "stat_p = stat_parity(preds, test_sens_adult)\n",
    "eq_op = eq_oppo(preds, test_sens_adult, test_y_adult)\n",
    "print(acc, stat_p, eq_op)\n",
    "\n",
    "\n",
    "\n",
    "# German 4 pts\n",
    "\n",
    "# initialize the model\n",
    "# TODO.\n",
    "\n",
    "model6 = LogisticRegression()\n",
    "\n",
    "# train/fit the model with train_x_german and train_y_german\n",
    "# TODO.\n",
    "\n",
    "model6.fit(train_x_german,train_y_german)\n",
    "\n",
    "# predict the outcome from test_x_german\n",
    "# TODO. The starter code below just indicate what you need to output in your code.\n",
    "preds = model6.predict(test_x_german)\n",
    "\n",
    "# report acc and two fairness metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_y_german, preds)\n",
    "stat_p = stat_parity(preds, test_sens_german)\n",
    "eq_op = eq_oppo(preds, test_sens_german, test_y_german)\n",
    "print(acc, stat_p, eq_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adcf17e",
   "metadata": {},
   "source": [
    "### According to the results, how are the accuracy, stat parity and eq oppo different from the original model? Does augmenting the dataset with synthetic data help in mitigating bias? Why or why not?\n",
    "### <span style=\"color:red\">Please type your response here.</span> 4 points\n",
    "The accuracies have some slight improvements after augmenting the data. The statistical parity and equalized opportunity all have decreased a little bit. Thus, augmenting the dataset with synthetic data does help in mitigating bias. Because the sensitive feature no longer becomes sensitive as the same data instance is duplicated and the sensitive is inversed. The dataset is now more balanced. Nevertheless, if the data itself still has bias, augmenting the dataset will not mitigating bias in this case and may exacerbate the biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f119a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
